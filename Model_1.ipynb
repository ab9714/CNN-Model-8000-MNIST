{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPWEMggL0w4kZfAUTaOfU3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Target: Reduce Number of Parameters below 8000 by changing CNN layers\n",
        "Results:\n",
        "\n",
        "Parameters: 5710\n",
        "\n",
        "Best Train Accuracy: 26.39\n",
        "\n",
        "Best Test Accuracy: 27.47\n",
        "\n",
        "Analysis: Very low accuracy need further modifications to transforms and training"
      ],
      "metadata": {
        "id": "Zc2JxYqYCTFF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyqpAiEG3ANh",
        "outputId": "3c91f54b-fad4-4fa5-b47f-92099c4721c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 26, 26]              90\n",
            "              ReLU-2           [-1, 10, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 10, 26, 26]              20\n",
            "           Dropout-4           [-1, 10, 26, 26]               0\n",
            "            Conv2d-5           [-1, 16, 24, 24]           1,440\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
            "           Dropout-8           [-1, 16, 24, 24]               0\n",
            "            Conv2d-9           [-1, 10, 24, 24]             160\n",
            "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
            "           Conv2d-11           [-1, 16, 10, 10]           1,440\n",
            "             ReLU-12           [-1, 16, 10, 10]               0\n",
            "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
            "          Dropout-14           [-1, 16, 10, 10]               0\n",
            "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
            "             ReLU-16             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
            "          Dropout-18             [-1, 16, 8, 8]               0\n",
            "        AvgPool2d-19             [-1, 16, 1, 1]               0\n",
            "           Conv2d-20             [-1, 10, 1, 1]             160\n",
            "================================================================\n",
            "Total params: 5,710\n",
            "Trainable params: 5,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.62\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.65\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=0 Loss=2.2430 Batch=468 Accuracy=26.06: 100%|██████████| 469/469 [00:35<00:00, 13.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2139, Accuracy: 2723/10000 (27.23%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=1 Loss=2.2286 Batch=468 Accuracy=25.95: 100%|██████████| 469/469 [00:37<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2140, Accuracy: 2716/10000 (27.16%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=2 Loss=2.2133 Batch=468 Accuracy=26.08: 100%|██████████| 469/469 [00:34<00:00, 13.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2138, Accuracy: 2737/10000 (27.37%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=3 Loss=2.2077 Batch=468 Accuracy=26.14: 100%|██████████| 469/469 [00:34<00:00, 13.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2142, Accuracy: 2742/10000 (27.42%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=4 Loss=2.2080 Batch=468 Accuracy=26.39: 100%|██████████| 469/469 [00:37<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2141, Accuracy: 2722/10000 (27.22%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=5 Loss=2.2397 Batch=468 Accuracy=26.09: 100%|██████████| 469/469 [00:35<00:00, 13.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2139, Accuracy: 2728/10000 (27.28%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=6 Loss=2.2362 Batch=468 Accuracy=26.11: 100%|██████████| 469/469 [00:33<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2137, Accuracy: 2726/10000 (27.26%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=7 Loss=2.2190 Batch=468 Accuracy=25.99: 100%|██████████| 469/469 [00:34<00:00, 13.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2142, Accuracy: 2727/10000 (27.27%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=8 Loss=2.2069 Batch=468 Accuracy=26.31: 100%|██████████| 469/469 [00:35<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2140, Accuracy: 2720/10000 (27.20%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=9 Loss=2.2194 Batch=468 Accuracy=26.08: 100%|██████████| 469/469 [00:34<00:00, 13.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2142, Accuracy: 2747/10000 (27.47%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=10 Loss=2.2416 Batch=468 Accuracy=26.04: 100%|██████████| 469/469 [00:35<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2140, Accuracy: 2723/10000 (27.23%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=11 Loss=2.2202 Batch=468 Accuracy=26.06: 100%|██████████| 469/469 [00:35<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2140, Accuracy: 2731/10000 (27.31%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=12 Loss=2.2304 Batch=468 Accuracy=26.03: 100%|██████████| 469/469 [00:35<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2141, Accuracy: 2721/10000 (27.21%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=13 Loss=2.2349 Batch=468 Accuracy=26.08: 100%|██████████| 469/469 [00:34<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2138, Accuracy: 2704/10000 (27.04%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=14 Loss=2.2067 Batch=468 Accuracy=26.05: 100%|██████████| 469/469 [00:34<00:00, 13.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2140, Accuracy: 2729/10000 (27.29%)\n",
            "\n",
            "Times achieved ≥99.4%: 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Initial Block: 28x28x1 -> 26x26x10\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.Dropout(0.01)  # Slightly increased dropout\n",
        "        )\n",
        "\n",
        "        # Conv Block 1: 26x26x10 -> 24x24x16\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(10, 16, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(0.01)\n",
        "        )\n",
        "\n",
        "        # Transition Block: 24x24x16 -> 12x12x10\n",
        "        self.trans1 = nn.Sequential(\n",
        "            nn.Conv2d(16, 10, kernel_size=1, bias=False),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Conv Block 2: 12x12x10 -> 10x10x16\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(10, 16, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(0.01)\n",
        "        )\n",
        "\n",
        "        # Conv Block 3: 10x10x16 -> 8x8x16\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(0.01)\n",
        "        )\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=8)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(16, 10, kernel_size=1, padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.trans1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.conv5(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, device, train_loader, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(data)\n",
        "        loss = F.nll_loss(y_pred, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(desc=f'Epoch={epoch} Loss={loss.item():.4f} Batch={batch_idx} Accuracy={100*correct/processed:.2f}')\n",
        "    return 100 * correct / processed\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100.*correct/len(test_loader.dataset):.2f}%)\\n')\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "def main():\n",
        "    torch.manual_seed(1)\n",
        "    batch_size = 128\n",
        "    epochs = 15\n",
        "\n",
        "    # Enhanced data augmentation with more aggressive transformations\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "                                       transforms.Resize((28, 28)),\n",
        "                                       transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
        "                                       ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True, transform=train_transform),\n",
        "        batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=test_transform),\n",
        "        batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
        "    )\n",
        "\n",
        "\n",
        "    from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = Net().to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "    summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "    accuracies_above_99_4 = 0\n",
        "    best_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        train_acc = train(model, device, train_loader, optimizer, scheduler, epoch)\n",
        "        test_acc = test(model, device, test_loader)\n",
        "        if test_acc >= 99.4:\n",
        "            accuracies_above_99_4 += 1\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Times achieved ≥99.4%: {accuracies_above_99_4}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}